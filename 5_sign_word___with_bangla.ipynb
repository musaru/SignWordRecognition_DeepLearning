{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhMPTKAwU_R3",
        "outputId": "65f3ab2a-7142-4886-80c7-424c69c8bbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.27-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zDLTyZxDU_Aj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAjVj7speUsP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os, cv2, math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from sklearn. model_selection import train_test_split\n",
        "from keras.layers import GlobalAveragePooling2D, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX-FyG6f-HY2"
      },
      "source": [
        "\n",
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaTnTnnGxDBs"
      },
      "source": [
        "##Segmentation Code Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z7LhkTww-Xi"
      },
      "outputs": [],
      "source": [
        "import cv2                 # working with, mainly resizing, images\n",
        "import numpy as np         # dealing with arrays\n",
        "import os                  # dealing with directories\n",
        "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy import expand_dims\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class skinDetector(object):\n",
        "\n",
        "  # class constructor\n",
        "  def __init__(self, imageName):\n",
        "      self.image = cv2.imread(imageName)\n",
        "      if self.image is None:\n",
        "          print(\"IMAGE NOT FOUND\")\n",
        "          exit(1)\n",
        "      # self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\n",
        "      self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
        "      self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
        "      self.binary_mask_image = self.HSV_image\n",
        "\n",
        "  # ================================================================================================================================\n",
        "  # function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
        "  def find_skin(self):\n",
        "      self.__color_segmentation()\n",
        "      output=self.__region_based_segmentation()\n",
        "      return output\n",
        "\n",
        "  # ================================================================================================================================\n",
        "  # Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
        "  # empirical tests and visual evaluation\n",
        "  def __color_segmentation(self):\n",
        "      lower_HSV_values = np.array([0, 40, 0], dtype=\"uint8\")\n",
        "      upper_HSV_values = np.array([25, 255, 255], dtype=\"uint8\")\n",
        "\n",
        "      lower_YCbCr_values = np.array((0, 138, 67), dtype=\"uint8\")\n",
        "      upper_YCbCr_values = np.array((255, 173, 133), dtype=\"uint8\")\n",
        "\n",
        "      # A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
        "      mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
        "      mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values)\n",
        "\n",
        "      self.binary_mask_image = cv2.add(mask_HSV, mask_YCbCr)\n",
        "      #self.binary_mask_image = mask_HSV\n",
        "      #self.binary_mask_image = mask_YCbCr\n",
        "\n",
        "  # ================================================================================================================================\n",
        "  # Function that applies Watershed and morphological operations on the thresholded image\n",
        "  def __region_based_segmentation(self):\n",
        "      # morphological operations\n",
        "      image_foreground = cv2.erode(self.binary_mask_image, None, iterations=3)  # remove noise\n",
        "      dilated_binary_image = cv2.dilate(self.binary_mask_image, None,\n",
        "                                        iterations=3)  # The background region is reduced a little because of the dilate operation\n",
        "      ret, image_background = cv2.threshold(dilated_binary_image, 1, 128,\n",
        "                                            cv2.THRESH_BINARY)  # set all background regions to 128\n",
        "\n",
        "      image_marker = cv2.add(image_foreground,\n",
        "                              image_background)  # add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
        "      image_marker32 = np.int32(image_marker)  # convert to 32SC1 format\n",
        "\n",
        "      cv2.watershed(self.image, image_marker32)\n",
        "      m = cv2.convertScaleAbs(image_marker32)  # convert back to uint8\n",
        "\n",
        "      # bitwise of the mask with the input image\n",
        "      ret, image_mask = cv2.threshold(m, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "      output = cv2.bitwise_and(self.image, self.image, mask=image_mask)\n",
        "\n",
        "      # show the images\n",
        "      #self.show_image(self.image)\n",
        "      #self.show_image(image_mask)\n",
        "      #return image_mask\n",
        "      #self.show_image(output)\n",
        "      return output\n",
        "\n",
        "  # ================================================================================================================================\n",
        "  def show_image(self, image):\n",
        "      cv2.imshow(\"Image\", image)\n",
        "      cv2.waitKey(0)\n",
        "      cv2.destroyWindow(\"Image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Pickle without Augmentation"
      ],
      "metadata": {
        "id": "mnoFqIos_rpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Directory=\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_sign_word\"\n",
        "\n",
        "Categories=['One','Two','Three','Four','Five']\n",
        "IMAGE_SIZE=60\n",
        "\n",
        "training_data = []\n",
        "i=0\n",
        "for c in Categories:\n",
        "    folder = os.path.join(Directory,c)\n",
        "    index = Categories.index(c)\n",
        "    \n",
        "    for img in os.listdir(folder):\n",
        "        image= os.path.join(folder,img)\n",
        "        img_arr=cv2.imread(image)\n",
        "        #detector = skinDetector(image)\n",
        "        #img_arr = detector.find_skin()\n",
        "        img_arr=cv2.resize(img_arr,(IMAGE_SIZE,IMAGE_SIZE))\n",
        "        training_data.append([img_arr, index])\n",
        "        #print(i)\n",
        "        i=i+1\n",
        "import random\n",
        "random.shuffle(training_data)\n",
        "for sample in training_data[:5]:\n",
        "    print(sample[1])\n",
        "\n",
        "\n",
        "B38TrX=[]\n",
        "B38Try=[]\n",
        "for features, label in training_data:\n",
        "    B38TrX.append(features)\n",
        "    B38Try.append(label)\n",
        "fswX=np.array(B38TrX)\n",
        "fswy=np.array(B38Try)\n",
        "\n",
        "import pickle\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswX.pickle\", \"wb\")\n",
        "pickle.dump(fswX,pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswy.pickle\", \"wb\")\n",
        "pickle.dump(fswy,pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQvCtUO_urT",
        "outputId": "1c1c06d8-c7de-4234-fdb2-bd1cfeba76eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRaining with augmentation"
      ],
      "metadata": {
        "id": "2Sj00zroT90s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import expand_dims\n",
        "Directory=\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_sign_word\"\n",
        "\n",
        "Categories=['One','Two','Three','Four','Five']\n",
        "Img_size=60\n",
        "Channel=3\n",
        "\n",
        "training_data = []\n",
        "i=0\n",
        "for c in Categories:\n",
        "    folder = os.path.join(Directory,c)\n",
        "    index = Categories.index(c)\n",
        "    \n",
        "    for img in os.listdir(folder):\n",
        "        image= os.path.join(folder,img)\n",
        "        img_arr=cv2.imread(image)\n",
        "        #detector = skinDetector(image)\n",
        "        #img_arr = detector.find_skin()\n",
        "        img_resized=cv2.resize(img_arr,(Img_size,Img_size))\n",
        "        training_data.append([img_resized, index])\n",
        "        \n",
        "        img_resized= expand_dims(img_resized, 0)\n",
        "        img_resized = expand_dims(img_resized, 3)\n",
        "        #print(img_resized.shape)\n",
        "        img_resized = img_resized.reshape(1, Img_size, Img_size, Channel)\n",
        "\n",
        "        datagenrot = ImageDataGenerator(rotation_range=39)\n",
        "        igr = datagenrot.flow(img_resized, batch_size=1)\n",
        "\n",
        "\n",
        "\n",
        "        datagenscal = ImageDataGenerator(zoom_range = .50)\n",
        "        igs = datagenscal.flow(img_resized, batch_size=1)\n",
        "\n",
        "        datagentrans = ImageDataGenerator(shear_range=-0.8)\n",
        "        igt = datagentrans.flow(img_resized, batch_size=1)\n",
        "\n",
        "        #datagentransshift = ImageDataGenerator(height_shift_range=0.2)\n",
        "        datagentransshift = ImageDataGenerator(width_shift_range=-0.3)\n",
        "        igtshift = datagentransshift.flow(img_resized, batch_size=1)\n",
        "        for i in range(3):\n",
        "            batch1 = igr.next()\n",
        "            Images = batch1[0].astype('uint8')\n",
        "            Images=Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "\n",
        "            batch3 = igs.next()\n",
        "            Images = batch3[0].astype('uint8')\n",
        "            Images = Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "            #plt.imshow(Images)\n",
        "            #plt.show()\n",
        "\n",
        "            batch2 = igt.next()\n",
        "            Images = batch2[0].astype('uint8')\n",
        "            Images = Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "            # plt.imshow(Images)\n",
        "            #plt.show()\n",
        "            #break\n",
        "            batch4 = igtshift.next()\n",
        "            Images = batch4[0].astype('uint8')\n",
        "            Images = Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "         \n",
        "\n",
        "        #print(i)\n",
        "        i=i+1\n",
        "\n",
        "\n",
        "import random\n",
        "random.shuffle(training_data)\n",
        "for sample in training_data[:5]:\n",
        "    print(sample[1])\n",
        "\n",
        "\n",
        "B38TrX=[]\n",
        "B38Try=[]\n",
        "for features, label in training_data:\n",
        "    B38TrX.append(features)\n",
        "    B38Try.append(label)\n",
        "fswX_aug=np.array(B38TrX)\n",
        "fswy_aug=np.array(B38Try)\n",
        "\n",
        "import pickle\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswX_aug.pickle\", \"wb\")\n",
        "pickle.dump(fswX_aug,pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswy_aug.pickle\", \"wb\")\n",
        "pickle.dump(fswy_aug,pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ik3KqizUuSx",
        "outputId": "b1ebc8ff-af2a-4322-b753-b9a6dbc2e4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST pickle without augmentation"
      ],
      "metadata": {
        "id": "BIbbyUsNVAj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Directory=\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_sign_word_Test\"\n",
        "Categories=['One','Two','Three','Four','Five']\n",
        "IMAGE_SIZE=60\n",
        "\n",
        "training_data = []\n",
        "i=0\n",
        "for c in Categories:\n",
        "    folder = os.path.join(Directory,c)\n",
        "    index = Categories.index(c)\n",
        "    \n",
        "    for img in os.listdir(folder):\n",
        "        image= os.path.join(folder,img)\n",
        "        img_arr=cv2.imread(image)\n",
        "        #detector = skinDetector(image)\n",
        "        #img_arr = detector.find_skin()\n",
        "        img_arr=cv2.resize(img_arr,(IMAGE_SIZE,IMAGE_SIZE))\n",
        "        training_data.append([img_arr, index])\n",
        "        #print(i)\n",
        "        i=i+1\n",
        "import random\n",
        "random.shuffle(training_data)\n",
        "for sample in training_data[:5]:\n",
        "    print(sample[1])\n",
        "\n",
        "\n",
        "B38TrX=[]\n",
        "B38Try=[]\n",
        "for features, label in training_data:\n",
        "    B38TrX.append(features)\n",
        "    B38Try.append(label)\n",
        "fswXTest=np.array(B38TrX)\n",
        "fswyTest=np.array(B38Try)\n",
        "\n",
        "import pickle\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswXTest.pickle\", \"wb\")\n",
        "pickle.dump(fswXTest,pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswyTest.pickle\", \"wb\")\n",
        "pickle.dump(fswyTest,pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjQzcekKVF7V",
        "outputId": "e0e63be5-48bf-4cf2-cc5a-d5573eef5862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n",
            "2\n",
            "4\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test pickle with augmentation"
      ],
      "metadata": {
        "id": "O3FhnlMlVHw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Directory=\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_sign_word_Test\"\n",
        "Categories=['One','Two','Three','Four','Five']\n",
        "Img_size=60\n",
        "\n",
        "training_data = []\n",
        "i=0\n",
        "for c in Categories:\n",
        "    folder = os.path.join(Directory,c)\n",
        "    index = Categories.index(c)\n",
        "    \n",
        "    for img in os.listdir(folder):\n",
        "        image= os.path.join(folder,img)\n",
        "        img_arr=cv2.imread(image)\n",
        "        #detector = skinDetector(image)\n",
        "        #img_arr = detector.find_skin()\n",
        "        img_resized=cv2.resize(img_arr,(Img_size,Img_size))\n",
        "        training_data.append([img_resized, index])\n",
        "        \n",
        "        img_resized= expand_dims(img_resized, 0)\n",
        "        img_resized = expand_dims(img_resized, 3)\n",
        "        #print(img_resized.shape)\n",
        "        img_resized = img_resized.reshape(1, Img_size, Img_size, Channel)\n",
        "\n",
        "        datagenrot = ImageDataGenerator(rotation_range=39)\n",
        "        igr = datagenrot.flow(img_resized, batch_size=1)\n",
        "\n",
        "\n",
        "\n",
        "        datagenscal = ImageDataGenerator(zoom_range = .50)\n",
        "        igs = datagenscal.flow(img_resized, batch_size=1)\n",
        "\n",
        "        datagentrans = ImageDataGenerator(height_shift_range=0.2)\n",
        "        igt = datagentrans.flow(img_resized, batch_size=1)\n",
        "\n",
        "        #datagentransshift = ImageDataGenerator(height_shift_range=0.2)\n",
        "        datagentransshift = ImageDataGenerator(width_shift_range=-0.3)\n",
        "        igtshift = datagentransshift.flow(img_resized, batch_size=1)\n",
        "        for i in range(3):\n",
        "            batch1 = igr.next()\n",
        "            Images = batch1[0].astype('uint8')\n",
        "            Images=Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "\n",
        "            batch3 = igs.next()\n",
        "            Images = batch3[0].astype('uint8')\n",
        "            Images = Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "            #plt.imshow(Images)\n",
        "            #plt.show()\n",
        "\n",
        "            batch2 = igt.next()\n",
        "            Images = batch2[0].astype('uint8')\n",
        "            Images = Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "            # plt.imshow(Images)\n",
        "            #plt.show()\n",
        "            #break\n",
        "            batch4 = igtshift.next()\n",
        "            Images = batch4[0].astype('uint8')\n",
        "            Images = Images.reshape(Img_size, Img_size, Channel)\n",
        "            training_data.append([Images, index])\n",
        "\n",
        "         \n",
        "\n",
        "        #print(i)\n",
        "        i=i+1\n",
        "\n",
        "\n",
        "import random\n",
        "random.shuffle(training_data)\n",
        "for sample in training_data[:5]:\n",
        "    print(sample[1])\n",
        "\n",
        "\n",
        "B38TrX=[]\n",
        "B38Try=[]\n",
        "for features, label in training_data:\n",
        "    B38TrX.append(features)\n",
        "    B38Try.append(label)\n",
        "fswX_aug_Test=np.array(B38TrX)\n",
        "fswy_aug_Test=np.array(B38Try)\n",
        "\n",
        "import pickle\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswX_aug_Test.pickle\", \"wb\")\n",
        "pickle.dump(fswX_aug_Test,pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "pickle_out=open(\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original/fswy_aug_Test.pickle\", \"wb\")\n",
        "pickle.dump(fswy_aug_Test,pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y54gbcGuVJ9O",
        "outputId": "d0cca5dd-2fc3-49c1-d216-d6207a2949ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Non_augmentData"
      ],
      "metadata": {
        "id": "KiE4BQBiTGVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "path=\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original\"\n",
        "\n",
        "X_train=pickle.load(open(os.path.join(path,\"fswX.pickle\"),\"rb\"))\n",
        "Y_train=pickle.load(open(os.path.join(path,\"fswy.pickle\"),\"rb\"))\n",
        "  \n",
        "\n",
        "#X_test=pickle.load(open(os.path.join(path,\"fswXTest.pickle\"),\"rb\"))\n",
        "#Y_test=pickle.load(open(os.path.join(path,\"fswyTest.pickle\"),\"rb\"))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm6OkDhhTLRg",
        "outputId": "941793a6-9c3f-4b2c-9231-2cc8ae4b3c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(217, 60, 60, 3)\n",
            "(217,)\n",
            "(15, 60, 60, 3)\n",
            "(15,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64x-eJjfpu2R"
      },
      "source": [
        "#Load Augmented Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYbOBzWxa24C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91cbb4e-3039-429f-ba34-dd44a7a7e065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2821, 60, 60, 3)\n",
            "(2821,)\n",
            "(195, 60, 60, 3)\n",
            "(195,)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "path=\"/content/drive/MyDrive/Colab Notebooks/Sign Language recognition/Dataset/JapanseWord/Five_original\"\n",
        "\n",
        "X_train=pickle.load(open(os.path.join(path,\"fswX_aug.pickle\"),\"rb\"))\n",
        "Y_train=pickle.load(open(os.path.join(path,\"fswy_aug.pickle\"),\"rb\"))\n",
        " \n",
        "X_test=pickle.load(open(os.path.join(path,\"fswX_aug_Test.pickle\"),\"rb\"))\n",
        "Y_test=pickle.load(open(os.path.join(path,\"fswy_aug_Test.pickle\"),\"rb\"))\n",
        "\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0hjB9Fqv8cL"
      },
      "source": [
        "#Load Not Segmentation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Divide test set into validation and finaltest"
      ],
      "metadata": {
        "id": "1Q1-b4vOCzRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hot Encoding"
      ],
      "metadata": {
        "id": "eXZ7pwHNCO4P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsuMR_wvbnUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f41e53d-1e2d-4225-9162-b4be19a4107d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x train shape (2821, 60, 60, 3)\n",
            "y train shape (2821,)\n",
            "x test shape (195, 60, 60, 3)\n",
            "y test shape (195,)\n",
            "Shape before one-hot encoding:  (2821,)\n",
            "Shape after one-hot encoding: for y train (2821, 5)\n",
            "Shape after one-hot encoding: for y test (195, 5)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test,y_train,y_test=X_train, X_test,Y_train,Y_test\n",
        "import os, cv2, math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "IMAGE_SIZE=60\n",
        "class_labels=5\n",
        "CHANNEL=3\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn. model_selection import train_test_split\n",
        "\n",
        "print('x train shape', x_train.shape)\n",
        "print('y train shape',y_train.shape)\n",
        "print('x test shape',x_test.shape)\n",
        "print('y test shape',y_test.shape)\n",
        "#\n",
        "y_train_ml=y_train\n",
        "y_test_ml=y_test\n",
        "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
        "#x_train = x_train.reshape(-1, 1600)\n",
        "#x_test = x_test.reshape(-1, 1600)\n",
        "\n",
        "#from sklearn import preprocessing\n",
        "#import numpy as np\n",
        "#x_train=preprocessing.StandardScaler().fit(x_train)\n",
        "#x_test=preprocessing.StandardScaler().fit(x_test)\n",
        "#x_train=np.array(x_train)\n",
        "#x_test=np.array(x_test)\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "#x_train /= 255.0\n",
        "#x_test /= 255.0\n",
        "#x_train/= 255.\n",
        "#x_train -= 0.5\n",
        "#x_train*= 2.\n",
        "\n",
        "#x_test/= 255.\n",
        "#x_test -= 0.5\n",
        "#x_test*= 2.\n",
        "\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 5\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: for y train\", y_train.shape)\n",
        "print(\"Shape after one-hot encoding: for y test\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##hot encoding for validationa and final test"
      ],
      "metadata": {
        "id": "1WLPWWp5DE0n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eQQ5O9TooxE"
      },
      "source": [
        "#All Package"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1tkA064Dsjcf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URUKBT6momtO"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import time\n",
        "import sklearn\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras import optimizers\n",
        "# import xgboost as xgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "#from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "#from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "import os, cv2, math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "images_train=x_train\n",
        "class_train=y_train \n",
        "images_test=x_test\n",
        "class_test=y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7TdLW2yVth3"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hadi code  93%"
      ],
      "metadata": {
        "id": "URWRHj2xyvZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NUM_EPOCH = 200\n",
        "# learning rate\n",
        "LEARN_RATE = 1.0e-4\n",
        "nb_classes=5\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNEL)))    \n",
        "model.add(Dropout(0.2))                                                                                                   \n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))  \n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))    \n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
        "model.add(Dropout(0.5))    \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(192, (1, 1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(5, (1, 1), padding='valid'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Activation('softmax'))  \n",
        "                             \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # Better loss function for neural networks\n",
        "              optimizer=Adam(learning_rate=LEARN_RATE), # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model\n",
        "\n",
        "\n",
        "model_details = model.fit(images_train, class_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = NUM_EPOCH, # number of iterations\n",
        "                    validation_data= (images_test, class_test),  verbose=1)"
      ],
      "metadata": {
        "id": "GtwYqUrRyxgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d65260-a62a-4c6c-eeec-236b98520019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 3s 77ms/step - loss: 1.6156 - accuracy: 0.2024 - val_loss: 1.6669 - val_accuracy: 0.2000\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.6103 - accuracy: 0.2201 - val_loss: 1.6184 - val_accuracy: 0.2000\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.6071 - accuracy: 0.2067 - val_loss: 1.6137 - val_accuracy: 0.1897\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.6044 - accuracy: 0.2400 - val_loss: 1.6074 - val_accuracy: 0.1897\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.6057 - accuracy: 0.2333 - val_loss: 1.6132 - val_accuracy: 0.2513\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.6020 - accuracy: 0.2499 - val_loss: 1.6040 - val_accuracy: 0.2051\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.5983 - accuracy: 0.2464 - val_loss: 1.6172 - val_accuracy: 0.2000\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.5891 - accuracy: 0.2634 - val_loss: 1.6199 - val_accuracy: 0.2000\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.5884 - accuracy: 0.2524 - val_loss: 1.5988 - val_accuracy: 0.2564\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.5604 - accuracy: 0.2765 - val_loss: 1.5968 - val_accuracy: 0.2154\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.5294 - accuracy: 0.3059 - val_loss: 1.6063 - val_accuracy: 0.2000\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.5029 - accuracy: 0.3197 - val_loss: 1.6205 - val_accuracy: 0.2000\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.4661 - accuracy: 0.3492 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.4184 - accuracy: 0.3853 - val_loss: 1.5915 - val_accuracy: 0.2000\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.3711 - accuracy: 0.4367 - val_loss: 1.5513 - val_accuracy: 0.2000\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.3067 - accuracy: 0.4878 - val_loss: 1.4948 - val_accuracy: 0.4103\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.2656 - accuracy: 0.5200 - val_loss: 1.5042 - val_accuracy: 0.3128\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.2044 - accuracy: 0.5675 - val_loss: 1.4934 - val_accuracy: 0.2205\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.1683 - accuracy: 0.5853 - val_loss: 1.4856 - val_accuracy: 0.2872\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.1086 - accuracy: 0.6370 - val_loss: 1.4669 - val_accuracy: 0.3026\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 1.0608 - accuracy: 0.6746 - val_loss: 1.4606 - val_accuracy: 0.2359\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.0300 - accuracy: 0.7022 - val_loss: 1.4614 - val_accuracy: 0.2359\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.9961 - accuracy: 0.7231 - val_loss: 1.4178 - val_accuracy: 0.2615\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.9616 - accuracy: 0.7451 - val_loss: 1.3909 - val_accuracy: 0.3641\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.9617 - accuracy: 0.7338 - val_loss: 1.3603 - val_accuracy: 0.4000\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.9147 - accuracy: 0.7696 - val_loss: 1.3585 - val_accuracy: 0.5538\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.8916 - accuracy: 0.7909 - val_loss: 1.3223 - val_accuracy: 0.6513\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.8620 - accuracy: 0.8036 - val_loss: 1.2977 - val_accuracy: 0.7897\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.8395 - accuracy: 0.8026 - val_loss: 1.2942 - val_accuracy: 0.7282\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.8040 - accuracy: 0.8373 - val_loss: 1.2853 - val_accuracy: 0.7128\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.7844 - accuracy: 0.8408 - val_loss: 1.2203 - val_accuracy: 0.7744\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.7619 - accuracy: 0.8476 - val_loss: 1.2124 - val_accuracy: 0.8564\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.7486 - accuracy: 0.8504 - val_loss: 1.2173 - val_accuracy: 0.8103\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.7417 - accuracy: 0.8550 - val_loss: 1.1869 - val_accuracy: 0.8564\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.7080 - accuracy: 0.8844 - val_loss: 1.1766 - val_accuracy: 0.8974\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.6853 - accuracy: 0.8823 - val_loss: 1.1787 - val_accuracy: 0.9128\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.6858 - accuracy: 0.8816 - val_loss: 1.1759 - val_accuracy: 0.8359\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.6718 - accuracy: 0.8873 - val_loss: 1.1460 - val_accuracy: 0.9026\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.6589 - accuracy: 0.8933 - val_loss: 1.1476 - val_accuracy: 0.9077\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.6323 - accuracy: 0.9128 - val_loss: 1.1133 - val_accuracy: 0.8667\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.6309 - accuracy: 0.9078 - val_loss: 1.0769 - val_accuracy: 0.9128\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.6262 - accuracy: 0.9089 - val_loss: 1.0705 - val_accuracy: 0.9231\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5992 - accuracy: 0.9185 - val_loss: 1.0454 - val_accuracy: 0.9385\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5859 - accuracy: 0.9252 - val_loss: 1.0683 - val_accuracy: 0.8821\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5822 - accuracy: 0.9270 - val_loss: 1.0546 - val_accuracy: 0.9077\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5599 - accuracy: 0.9319 - val_loss: 1.0307 - val_accuracy: 0.9231\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5539 - accuracy: 0.9358 - val_loss: 0.9936 - val_accuracy: 0.9590\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5304 - accuracy: 0.9436 - val_loss: 1.0295 - val_accuracy: 0.9487\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5272 - accuracy: 0.9454 - val_loss: 1.0342 - val_accuracy: 0.9077\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5272 - accuracy: 0.9429 - val_loss: 0.9936 - val_accuracy: 0.9487\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.5173 - accuracy: 0.9461 - val_loss: 0.9865 - val_accuracy: 0.9487\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5097 - accuracy: 0.9454 - val_loss: 0.9985 - val_accuracy: 0.9282\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5359 - accuracy: 0.9344 - val_loss: 0.9847 - val_accuracy: 0.9385\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.5014 - accuracy: 0.9497 - val_loss: 0.9566 - val_accuracy: 0.9590\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4778 - accuracy: 0.9585 - val_loss: 0.9285 - val_accuracy: 0.9538\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4616 - accuracy: 0.9617 - val_loss: 0.9647 - val_accuracy: 0.9436\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4648 - accuracy: 0.9589 - val_loss: 0.9420 - val_accuracy: 0.9487\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4518 - accuracy: 0.9642 - val_loss: 0.9135 - val_accuracy: 0.9590\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4428 - accuracy: 0.9688 - val_loss: 0.9746 - val_accuracy: 0.9231\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4440 - accuracy: 0.9656 - val_loss: 0.9154 - val_accuracy: 0.9538\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4352 - accuracy: 0.9677 - val_loss: 0.8970 - val_accuracy: 0.9538\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4278 - accuracy: 0.9713 - val_loss: 0.9271 - val_accuracy: 0.9487\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.4273 - accuracy: 0.9731 - val_loss: 0.9321 - val_accuracy: 0.9487\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4257 - accuracy: 0.9663 - val_loss: 0.8939 - val_accuracy: 0.9538\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4235 - accuracy: 0.9709 - val_loss: 0.8702 - val_accuracy: 0.9692\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4050 - accuracy: 0.9748 - val_loss: 0.9483 - val_accuracy: 0.9385\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.4037 - accuracy: 0.9720 - val_loss: 0.8759 - val_accuracy: 0.9538\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3917 - accuracy: 0.9794 - val_loss: 0.9039 - val_accuracy: 0.9590\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3908 - accuracy: 0.9798 - val_loss: 0.8872 - val_accuracy: 0.9487\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3848 - accuracy: 0.9770 - val_loss: 0.8893 - val_accuracy: 0.9641\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3840 - accuracy: 0.9784 - val_loss: 0.9089 - val_accuracy: 0.9538\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3828 - accuracy: 0.9809 - val_loss: 0.8793 - val_accuracy: 0.9590\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3745 - accuracy: 0.9770 - val_loss: 0.8718 - val_accuracy: 0.9744\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3721 - accuracy: 0.9819 - val_loss: 0.8687 - val_accuracy: 0.9590\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3695 - accuracy: 0.9805 - val_loss: 0.8659 - val_accuracy: 0.9487\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3587 - accuracy: 0.9855 - val_loss: 0.8254 - val_accuracy: 0.9692\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3515 - accuracy: 0.9851 - val_loss: 0.8463 - val_accuracy: 0.9744\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3551 - accuracy: 0.9855 - val_loss: 0.8218 - val_accuracy: 0.9692\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3570 - accuracy: 0.9833 - val_loss: 0.8265 - val_accuracy: 0.9692\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3608 - accuracy: 0.9805 - val_loss: 0.8682 - val_accuracy: 0.9590\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3498 - accuracy: 0.9855 - val_loss: 0.7922 - val_accuracy: 0.9641\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3411 - accuracy: 0.9830 - val_loss: 0.8254 - val_accuracy: 0.9795\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3402 - accuracy: 0.9862 - val_loss: 0.8267 - val_accuracy: 0.9692\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3295 - accuracy: 0.9869 - val_loss: 0.8137 - val_accuracy: 0.9692\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3358 - accuracy: 0.9862 - val_loss: 0.7971 - val_accuracy: 0.9897\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3234 - accuracy: 0.9890 - val_loss: 0.8259 - val_accuracy: 0.9744\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3244 - accuracy: 0.9872 - val_loss: 0.8292 - val_accuracy: 0.9795\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3268 - accuracy: 0.9872 - val_loss: 0.7812 - val_accuracy: 0.9744\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3228 - accuracy: 0.9872 - val_loss: 0.7434 - val_accuracy: 0.9795\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3239 - accuracy: 0.9848 - val_loss: 0.8071 - val_accuracy: 0.9744\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.3131 - accuracy: 0.9887 - val_loss: 0.8144 - val_accuracy: 0.9897\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3041 - accuracy: 0.9890 - val_loss: 0.7920 - val_accuracy: 0.9846\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3126 - accuracy: 0.9855 - val_loss: 0.7848 - val_accuracy: 0.9692\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3126 - accuracy: 0.9879 - val_loss: 0.7226 - val_accuracy: 0.9795\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3057 - accuracy: 0.9890 - val_loss: 0.7734 - val_accuracy: 0.9897\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2968 - accuracy: 0.9876 - val_loss: 0.7858 - val_accuracy: 0.9590\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.3041 - accuracy: 0.9862 - val_loss: 0.8445 - val_accuracy: 0.9385\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.3080 - accuracy: 0.9904 - val_loss: 0.8047 - val_accuracy: 0.9795\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2885 - accuracy: 0.9915 - val_loss: 0.7595 - val_accuracy: 0.9846\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2801 - accuracy: 0.9897 - val_loss: 0.7926 - val_accuracy: 0.9846\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2824 - accuracy: 0.9897 - val_loss: 0.7611 - val_accuracy: 0.9795\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2803 - accuracy: 0.9918 - val_loss: 0.7673 - val_accuracy: 0.9795\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2837 - accuracy: 0.9915 - val_loss: 0.7658 - val_accuracy: 0.9744\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2865 - accuracy: 0.9926 - val_loss: 0.7823 - val_accuracy: 0.9744\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2761 - accuracy: 0.9908 - val_loss: 0.7641 - val_accuracy: 0.9795\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2662 - accuracy: 0.9915 - val_loss: 0.7511 - val_accuracy: 0.9795\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2738 - accuracy: 0.9901 - val_loss: 0.7122 - val_accuracy: 0.9897\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2648 - accuracy: 0.9890 - val_loss: 0.7602 - val_accuracy: 0.9846\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2659 - accuracy: 0.9915 - val_loss: 0.7688 - val_accuracy: 0.9795\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2702 - accuracy: 0.9897 - val_loss: 0.7724 - val_accuracy: 0.9795\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2657 - accuracy: 0.9904 - val_loss: 0.7461 - val_accuracy: 0.9795\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2670 - accuracy: 0.9908 - val_loss: 0.7353 - val_accuracy: 0.9795\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2557 - accuracy: 0.9915 - val_loss: 0.7709 - val_accuracy: 0.9692\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2538 - accuracy: 0.9933 - val_loss: 0.7487 - val_accuracy: 0.9795\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2592 - accuracy: 0.9887 - val_loss: 0.8453 - val_accuracy: 0.9487\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2740 - accuracy: 0.9883 - val_loss: 0.7475 - val_accuracy: 0.9795\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2602 - accuracy: 0.9897 - val_loss: 0.7148 - val_accuracy: 0.9846\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2475 - accuracy: 0.9911 - val_loss: 0.7465 - val_accuracy: 0.9795\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2512 - accuracy: 0.9901 - val_loss: 0.7578 - val_accuracy: 0.9487\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2475 - accuracy: 0.9926 - val_loss: 0.7599 - val_accuracy: 0.9795\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2453 - accuracy: 0.9908 - val_loss: 0.7229 - val_accuracy: 0.9795\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2384 - accuracy: 0.9918 - val_loss: 0.7265 - val_accuracy: 0.9795\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2348 - accuracy: 0.9926 - val_loss: 0.7012 - val_accuracy: 0.9795\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2335 - accuracy: 0.9926 - val_loss: 0.7213 - val_accuracy: 0.9692\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2421 - accuracy: 0.9904 - val_loss: 0.7761 - val_accuracy: 0.9641\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2465 - accuracy: 0.9911 - val_loss: 0.7546 - val_accuracy: 0.9795\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2460 - accuracy: 0.9908 - val_loss: 0.7039 - val_accuracy: 0.9949\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2289 - accuracy: 0.9911 - val_loss: 0.6939 - val_accuracy: 0.9795\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2264 - accuracy: 0.9933 - val_loss: 0.7119 - val_accuracy: 0.9744\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2265 - accuracy: 0.9911 - val_loss: 0.7113 - val_accuracy: 0.9744\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2444 - accuracy: 0.9901 - val_loss: 0.7284 - val_accuracy: 0.9692\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2278 - accuracy: 0.9926 - val_loss: 0.6619 - val_accuracy: 0.9795\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2238 - accuracy: 0.9922 - val_loss: 0.6845 - val_accuracy: 0.9897\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2223 - accuracy: 0.9926 - val_loss: 0.6956 - val_accuracy: 0.9846\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2236 - accuracy: 0.9911 - val_loss: 0.6839 - val_accuracy: 0.9641\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2249 - accuracy: 0.9918 - val_loss: 0.7285 - val_accuracy: 0.9897\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2191 - accuracy: 0.9926 - val_loss: 0.7007 - val_accuracy: 0.9846\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2188 - accuracy: 0.9908 - val_loss: 0.6979 - val_accuracy: 0.9795\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2138 - accuracy: 0.9929 - val_loss: 0.7019 - val_accuracy: 0.9846\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.2140 - accuracy: 0.9936 - val_loss: 0.6992 - val_accuracy: 0.9846\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2135 - accuracy: 0.9933 - val_loss: 0.6663 - val_accuracy: 0.9897\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2120 - accuracy: 0.9918 - val_loss: 0.6618 - val_accuracy: 0.9846\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2140 - accuracy: 0.9936 - val_loss: 0.6536 - val_accuracy: 0.9897\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2099 - accuracy: 0.9926 - val_loss: 0.6658 - val_accuracy: 0.9795\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2112 - accuracy: 0.9904 - val_loss: 0.6766 - val_accuracy: 0.9949\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2121 - accuracy: 0.9940 - val_loss: 0.7961 - val_accuracy: 0.9538\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2302 - accuracy: 0.9908 - val_loss: 0.7195 - val_accuracy: 0.9744\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2403 - accuracy: 0.9862 - val_loss: 0.7038 - val_accuracy: 0.9795\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2128 - accuracy: 0.9936 - val_loss: 0.6735 - val_accuracy: 0.9897\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2041 - accuracy: 0.9933 - val_loss: 0.6874 - val_accuracy: 0.9744\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.2090 - accuracy: 0.9901 - val_loss: 0.6916 - val_accuracy: 0.9744\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2194 - accuracy: 0.9894 - val_loss: 0.6624 - val_accuracy: 0.9744\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2033 - accuracy: 0.9933 - val_loss: 0.6458 - val_accuracy: 0.9897\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2119 - accuracy: 0.9926 - val_loss: 0.6407 - val_accuracy: 0.9795\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.2000 - accuracy: 0.9936 - val_loss: 0.6811 - val_accuracy: 0.9846\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.2158 - accuracy: 0.9897 - val_loss: 0.6932 - val_accuracy: 0.9744\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1998 - accuracy: 0.9929 - val_loss: 0.7094 - val_accuracy: 0.9641\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.1899 - accuracy: 0.9947 - val_loss: 0.6789 - val_accuracy: 0.9846\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1916 - accuracy: 0.9926 - val_loss: 0.6768 - val_accuracy: 0.9795\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1874 - accuracy: 0.9936 - val_loss: 0.6682 - val_accuracy: 0.9846\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1886 - accuracy: 0.9936 - val_loss: 0.6398 - val_accuracy: 0.9795\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1834 - accuracy: 0.9922 - val_loss: 0.6415 - val_accuracy: 0.9846\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1826 - accuracy: 0.9933 - val_loss: 0.6498 - val_accuracy: 0.9795\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.1830 - accuracy: 0.9936 - val_loss: 0.6622 - val_accuracy: 0.9846\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1839 - accuracy: 0.9933 - val_loss: 0.6792 - val_accuracy: 0.9846\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1881 - accuracy: 0.9918 - val_loss: 0.6476 - val_accuracy: 0.9795\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1838 - accuracy: 0.9929 - val_loss: 0.6580 - val_accuracy: 0.9897\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1799 - accuracy: 0.9933 - val_loss: 0.6873 - val_accuracy: 0.9897\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1829 - accuracy: 0.9918 - val_loss: 0.6433 - val_accuracy: 0.9795\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1859 - accuracy: 0.9911 - val_loss: 0.6423 - val_accuracy: 0.9846\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1868 - accuracy: 0.9929 - val_loss: 0.6738 - val_accuracy: 0.9897\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1859 - accuracy: 0.9929 - val_loss: 0.6584 - val_accuracy: 0.9897\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1787 - accuracy: 0.9965 - val_loss: 0.6488 - val_accuracy: 0.9897\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1933 - accuracy: 0.9922 - val_loss: 0.6828 - val_accuracy: 0.9846\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1912 - accuracy: 0.9918 - val_loss: 0.6728 - val_accuracy: 0.9538\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.1775 - accuracy: 0.9936 - val_loss: 0.6691 - val_accuracy: 0.9795\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1836 - accuracy: 0.9933 - val_loss: 0.6729 - val_accuracy: 0.9282\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.1866 - accuracy: 0.9908 - val_loss: 0.6322 - val_accuracy: 0.9795\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.1796 - accuracy: 0.9904 - val_loss: 0.6273 - val_accuracy: 0.9795\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.1729 - accuracy: 0.9922 - val_loss: 0.6488 - val_accuracy: 0.9795\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 0.1751 - accuracy: 0.9929 - val_loss: 0.6301 - val_accuracy: 0.9744\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1686 - accuracy: 0.9918 - val_loss: 0.6523 - val_accuracy: 0.9846\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1772 - accuracy: 0.9926 - val_loss: 0.6323 - val_accuracy: 0.9846\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1717 - accuracy: 0.9933 - val_loss: 0.6648 - val_accuracy: 0.9846\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1657 - accuracy: 0.9929 - val_loss: 0.6489 - val_accuracy: 0.9744\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1664 - accuracy: 0.9943 - val_loss: 0.6490 - val_accuracy: 0.9795\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.1755 - accuracy: 0.9933 - val_loss: 0.6308 - val_accuracy: 0.9744\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1798 - accuracy: 0.9901 - val_loss: 0.6298 - val_accuracy: 0.9692\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1694 - accuracy: 0.9954 - val_loss: 0.6316 - val_accuracy: 0.9487\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1735 - accuracy: 0.9926 - val_loss: 0.6537 - val_accuracy: 0.9846\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1682 - accuracy: 0.9929 - val_loss: 0.6042 - val_accuracy: 0.9744\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1663 - accuracy: 0.9940 - val_loss: 0.6037 - val_accuracy: 0.9846\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1606 - accuracy: 0.9922 - val_loss: 0.6009 - val_accuracy: 0.9846\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.1672 - accuracy: 0.9929 - val_loss: 0.6402 - val_accuracy: 0.9846\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1589 - accuracy: 0.9940 - val_loss: 0.6203 - val_accuracy: 0.9897\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1574 - accuracy: 0.9933 - val_loss: 0.6129 - val_accuracy: 0.9795\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1634 - accuracy: 0.9911 - val_loss: 0.6524 - val_accuracy: 0.9692\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1669 - accuracy: 0.9926 - val_loss: 0.5968 - val_accuracy: 0.9744\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 0.1583 - accuracy: 0.9933 - val_loss: 0.6234 - val_accuracy: 0.9846\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 2s 67ms/step - loss: 0.1558 - accuracy: 0.9926 - val_loss: 0.6127 - val_accuracy: 0.9795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#had for training validation and test"
      ],
      "metadata": {
        "id": "mZDDFcwlNsGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#confusion matrix"
      ],
      "metadata": {
        "id": "tq4uxfds31WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "IMG_SIZE=IMAGE_SIZE\n",
        "class_names=['One','Two','Three','Four','Five']\n",
        "x_test = x_test.reshape(x_test.shape[0], IMG_SIZE, IMG_SIZE, 3)\n",
        "prediction=model.predict(x_test, batch_size=128, verbose=0)\n",
        "#prediction_class=success_rate.predict_classes(x_test, batch_size=128, verbose=0)\n",
        "rounded_predictions=np.argmax(prediction, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix using sklearn.metrics\n",
        "cm = sklearn.metrics.confusion_matrix(y_test_ml, rounded_predictions)\n",
        "    \n",
        "figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "\n",
        "\n",
        "#cm_image = plot_to_image(figure)\n",
        "\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "#with file_writer_cm.as_default():\n",
        "      #tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "metadata": {
        "id": "elc6sMmX3tso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a026cc3-1a88-4252-a067-11e9210c13ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x1152 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "result_rf = confusion_matrix(y_test_ml, rounded_predictions)\n",
        "\n",
        "result1_rf = classification_report(y_test_ml, rounded_predictions)\n",
        "print(\"\\nClassification Report for pca & random forest:\",)\n",
        "print (result1_rf)\n",
        "\n"
      ],
      "metadata": {
        "id": "NCFYu6LC4a4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f48f3ff-b400-4f70-d6a5-2446423fc478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for pca & random forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        39\n",
            "           1       0.97      0.95      0.96        39\n",
            "           2       0.97      0.97      0.97        39\n",
            "           3       0.97      1.00      0.99        39\n",
            "           4       1.00      0.97      0.99        39\n",
            "\n",
            "    accuracy                           0.98       195\n",
            "   macro avg       0.98      0.98      0.98       195\n",
            "weighted avg       0.98      0.98      0.98       195\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model_details\n",
        "loss = history.history['loss']\n",
        "\n",
        "loss_val = history.history['val_loss']\n",
        "\n",
        "epochs = range(0,200)\n",
        "\n",
        "plt.plot(epochs, loss, 'g', label='Training Loss')\n",
        "\n",
        "plt.plot(epochs, loss_val, 'b', label='Test Loss')\n",
        "\n",
        "plt.title('Training and Test Loss')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dZYm7sGHVz0D",
        "outputId": "a3fbc831-c001-4ed4-a249-85be11683e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['accuracy']\n",
        "\n",
        "loss_val = history.history['val_accuracy']\n",
        "print(loss_val)\n",
        "\n",
        "epochs = range(0,200)\n",
        "\n",
        "plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n",
        "\n",
        "plt.plot(epochs, loss_val, 'b', label='Test Accuracy')\n",
        "\n",
        "plt.title('Training and Test Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "BjJZd-sKV3dj",
        "outputId": "8f9d596c-5952-455d-ce23-277a3d9742cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20000000298023224, 0.20000000298023224, 0.18974359333515167, 0.18974359333515167, 0.25128206610679626, 0.20512820780277252, 0.20000000298023224, 0.20000000298023224, 0.25641027092933655, 0.2153846174478531, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.41025641560554504, 0.31282052397727966, 0.22051282227039337, 0.28717949986457825, 0.3025641143321991, 0.23589743673801422, 0.23589743673801422, 0.26153847575187683, 0.3641025722026825, 0.4000000059604645, 0.5538461804389954, 0.6512820720672607, 0.7897436022758484, 0.728205144405365, 0.7128205299377441, 0.7743589878082275, 0.8564102649688721, 0.8102564215660095, 0.8564102649688721, 0.8974359035491943, 0.9128205180168152, 0.8358974456787109, 0.9025641083717346, 0.9076923131942749, 0.8666666746139526, 0.9128205180168152, 0.9230769276618958, 0.9384615421295166, 0.8820512890815735, 0.9076923131942749, 0.9230769276618958, 0.9589743614196777, 0.9487179517745972, 0.9076923131942749, 0.9487179517745972, 0.9487179517745972, 0.928205132484436, 0.9384615421295166, 0.9589743614196777, 0.9538461565971375, 0.9435897469520569, 0.9487179517745972, 0.9589743614196777, 0.9230769276618958, 0.9538461565971375, 0.9538461565971375, 0.9487179517745972, 0.9487179517745972, 0.9538461565971375, 0.9692307710647583, 0.9384615421295166, 0.9538461565971375, 0.9589743614196777, 0.9487179517745972, 0.964102566242218, 0.9538461565971375, 0.9589743614196777, 0.9743589758872986, 0.9589743614196777, 0.9487179517745972, 0.9692307710647583, 0.9743589758872986, 0.9692307710647583, 0.9692307710647583, 0.9589743614196777, 0.964102566242218, 0.9794871807098389, 0.9692307710647583, 0.9692307710647583, 0.9897435903549194, 0.9743589758872986, 0.9794871807098389, 0.9743589758872986, 0.9794871807098389, 0.9743589758872986, 0.9897435903549194, 0.9846153855323792, 0.9692307710647583, 0.9794871807098389, 0.9897435903549194, 0.9589743614196777, 0.9384615421295166, 0.9794871807098389, 0.9846153855323792, 0.9846153855323792, 0.9794871807098389, 0.9794871807098389, 0.9743589758872986, 0.9743589758872986, 0.9794871807098389, 0.9794871807098389, 0.9897435903549194, 0.9846153855323792, 0.9794871807098389, 0.9794871807098389, 0.9794871807098389, 0.9794871807098389, 0.9692307710647583, 0.9794871807098389, 0.9487179517745972, 0.9794871807098389, 0.9846153855323792, 0.9794871807098389, 0.9487179517745972, 0.9794871807098389, 0.9794871807098389, 0.9794871807098389, 0.9794871807098389, 0.9692307710647583, 0.964102566242218, 0.9794871807098389, 0.9948717951774597, 0.9794871807098389, 0.9743589758872986, 0.9743589758872986, 0.9692307710647583, 0.9794871807098389, 0.9897435903549194, 0.9846153855323792, 0.964102566242218, 0.9897435903549194, 0.9846153855323792, 0.9794871807098389, 0.9846153855323792, 0.9846153855323792, 0.9897435903549194, 0.9846153855323792, 0.9897435903549194, 0.9794871807098389, 0.9948717951774597, 0.9538461565971375, 0.9743589758872986, 0.9794871807098389, 0.9897435903549194, 0.9743589758872986, 0.9743589758872986, 0.9743589758872986, 0.9897435903549194, 0.9794871807098389, 0.9846153855323792, 0.9743589758872986, 0.964102566242218, 0.9846153855323792, 0.9794871807098389, 0.9846153855323792, 0.9794871807098389, 0.9846153855323792, 0.9794871807098389, 0.9846153855323792, 0.9846153855323792, 0.9794871807098389, 0.9897435903549194, 0.9897435903549194, 0.9794871807098389, 0.9846153855323792, 0.9897435903549194, 0.9897435903549194, 0.9897435903549194, 0.9846153855323792, 0.9538461565971375, 0.9794871807098389, 0.928205132484436, 0.9794871807098389, 0.9794871807098389, 0.9794871807098389, 0.9743589758872986, 0.9846153855323792, 0.9846153855323792, 0.9846153855323792, 0.9743589758872986, 0.9794871807098389, 0.9743589758872986, 0.9692307710647583, 0.9487179517745972, 0.9846153855323792, 0.9743589758872986, 0.9846153855323792, 0.9846153855323792, 0.9846153855323792, 0.9897435903549194, 0.9794871807098389, 0.9692307710647583, 0.9743589758872986, 0.9846153855323792, 0.9794871807098389]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#had for Training Valid and Test"
      ],
      "metadata": {
        "id": "3NFB6svqN07o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NUM_EPOCH = 500\n",
        "# learning rate\n",
        "LEARN_RATE = 1.0e-4\n",
        "nb_classes=38\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Image Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(images_train)\n",
        "\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNEL)))    \n",
        "model.add(Dropout(0.2))                                                                                                   \n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))  \n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))    \n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
        "model.add(Dropout(0.5))    \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(192, (1, 1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(38, (1, 1), padding='valid'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Activation('softmax'))  \n",
        "                             \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # Better loss function for neural networks\n",
        "              optimizer=Adam(learning_rate=LEARN_RATE), # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model\n",
        "\n",
        "\n",
        "model_details = model.fit(images_train, class_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = NUM_EPOCH, # number of iterations\n",
        "                    validation_data= (X_valid, y_validenc),  verbose=1)  "
      ],
      "metadata": {
        "id": "8TKrk0isN3-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "636b6e5b-ba72-4d1d-8a67-a6b9d7d23513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c10d898a91f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     validation_data= (X_valid, y_validenc),  verbose=1)  \n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_valid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37']\n",
        "IMG_SIZE=124\n",
        "x_test = x_test.reshape(x_test.shape[0], IMG_SIZE, IMG_SIZE, 3)\n",
        "prediction=model.predict( X_valid, batch_size=128, verbose=1)\n",
        "#prediction_class=success_rate.predict_classes(x_test, batch_size=128, verbose=0)\n",
        "rounded_predictions=np.argmax(prediction, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix using sklearn.metrics\n",
        "cm = sklearn.metrics.confusion_matrix(y_valid, rounded_predictions)\n",
        "    \n",
        "figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "\n",
        "\n",
        "#cm_image = plot_to_image(figure)\n",
        "\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "#with file_writer_cm.as_default():\n",
        "      #tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n"
      ],
      "metadata": {
        "id": "9_XR6fJITppJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "result_rf = confusion_matrix(y_valid, rounded_predictions)\n",
        "\n",
        "result1_rf = classification_report(y_valid, rounded_predictions)\n",
        "print(\"\\nClassification Report for pca & random forest:\",)\n",
        "print (result1_rf)\n"
      ],
      "metadata": {
        "id": "8dGg7WzdTsz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37']\n",
        "IMG_SIZE=124\n",
        "x_test = x_test.reshape(x_test.shape[0], IMG_SIZE, IMG_SIZE, 3)\n",
        "prediction=model.predict( X_ftest, batch_size=128, verbose=1)\n",
        "#prediction_class=success_rate.predict_classes(x_test, batch_size=128, verbose=0)\n",
        "rounded_predictions=np.argmax(prediction, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix using sklearn.metrics\n",
        "cm = sklearn.metrics.confusion_matrix(y_ftest, rounded_predictions)\n",
        "    \n",
        "figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "\n",
        "\n",
        "#cm_image = plot_to_image(figure)\n",
        "\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "#with file_writer_cm.as_default():\n",
        "      #tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "metadata": {
        "id": "F7lns6JhfpVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "result_rf = confusion_matrix(y_ftest, rounded_predictions)\n",
        "\n",
        "result1_rf = classification_report(y_ftest, rounded_predictions)\n",
        "print(\"\\nClassification Report for pca & random forest:\",)\n",
        "print (result1_rf)"
      ],
      "metadata": {
        "id": "W1VsOFryfzB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhvMkYagODcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    import itertools\n",
        "    import io\n",
        "    \"\"\"\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    \"\"\"\n",
        "    \n",
        "    figure = plt.figure(figsize=(16, 16))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    \n",
        "    # Normalize the confusion matrix.\n",
        "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure\n",
        "from datetime import datetime\n",
        "import keras\n",
        "logdir = \"logs/fit\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir = logdir, histogram_freq = 1)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    import io\n",
        "    \"\"\"\n",
        "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\n",
        "    \"\"\"\n",
        "    \n",
        "    buf = io.BytesIO()\n",
        "    \n",
        "    # Use plt.savefig to save the plot to a PNG in memory.\n",
        "    plt.savefig(buf, format='png')\n",
        "    \n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    \n",
        "    # Use tf.image.decode_png to convert the PNG buffer\n",
        "    # to a TF image. Make sure you use 4 channels.\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    \n",
        "    # Use tf.expand_dims to add the batch dimension\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    \n",
        "    return image\n",
        "epoch=10\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "    \n",
        "    # Use the model to predict the values from the test_images.\n",
        "    test_pred_raw = model.predict(test_images)\n",
        "    \n",
        "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "    \n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "    \n",
        "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "metadata": {
        "id": "I1Sm13W14eMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history=model.fit_generator(datagen.flow(images_train, class_train, batch_size = 128),\n",
        "                    steps_per_epoch = len(images_train) / 32, # number of samples per gradient update\n",
        "                    epochs = 500, # number of iterations\n",
        "                    validation_data= (images_test, class_test),\n",
        "                    \n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "id": "gLp6ikRe3QaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(images_test.shape)\n",
        "print(class_test.shape)\n",
        "print(images_train.shape)\n",
        "print(class_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM23FrnpZi4x",
        "outputId": "0d8c9c54-726c-4f91-e238-21b347855914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1520, 124, 124, 3)\n",
            "(1520, 38)\n",
            "(11071, 124, 124, 3)\n",
            "(11071, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN with SVM"
      ],
      "metadata": {
        "id": "SNSKvwNG6G0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "NUM_EPOCH = 350\n",
        "# learning rate\n",
        "LEARN_RATE = 1.0e-4\n",
        "nb_classes=38\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Image Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=[0.2,1.0],\n",
        "    zoom_range=[0.5,1.0]\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(images_train)\n",
        "\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNEL)))    \n",
        "model.add(Dropout(0.2))                                                                                                   \n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))  \n",
        "model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))    \n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
        "model.add(Dropout(0.5))    \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(192, (1, 1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(GlobalAveragePooling2D())run kora hoece 0.026\n",
        "#model.add(Activation('softmax')) \n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#model.add(Activation('softmax')) \n",
        "\n",
        "#model.add(Conv2D(38, (1, 1), padding='valid', tf.keras.regularizers.l2(0.01))\n",
        "model.add(Dense(38, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(GlobalAveragePooling2D())\n",
        "\n",
        "#model.add(Activation('softmax'))  \n",
        "                             \n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='squared_hinge', # Better loss function for neural networks\n",
        "              \n",
        "              # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model\n",
        "\n",
        "\n",
        "model_details = model.fit(images_train, class_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = NUM_EPOCH,validation_data= (images_test, class_test),  verbose=1)"
      ],
      "metadata": {
        "id": "geUpbSDZ6LF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b205920f-473d-42f1-ff46-ce6ae0b18d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "87/87 [==============================] - 38s 318ms/step - loss: 1.1426 - accuracy: 0.0260 - val_loss: 1.0763 - val_accuracy: 0.0263\n",
            "Epoch 2/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0262 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 3/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0831 - accuracy: 0.0279 - val_loss: 1.0996 - val_accuracy: 0.0263\n",
            "Epoch 4/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0984 - accuracy: 0.0271 - val_loss: 1.0972 - val_accuracy: 0.0263\n",
            "Epoch 5/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0961 - accuracy: 0.0271 - val_loss: 1.0952 - val_accuracy: 0.0263\n",
            "Epoch 6/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0943 - accuracy: 0.0271 - val_loss: 1.0936 - val_accuracy: 0.0263\n",
            "Epoch 7/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0928 - accuracy: 0.0271 - val_loss: 1.0922 - val_accuracy: 0.0263\n",
            "Epoch 8/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0915 - accuracy: 0.0271 - val_loss: 1.0910 - val_accuracy: 0.0263\n",
            "Epoch 9/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0903 - accuracy: 0.0271 - val_loss: 1.0898 - val_accuracy: 0.0263\n",
            "Epoch 10/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0892 - accuracy: 0.0271 - val_loss: 1.0888 - val_accuracy: 0.0263\n",
            "Epoch 11/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0882 - accuracy: 0.0271 - val_loss: 1.0878 - val_accuracy: 0.0263\n",
            "Epoch 12/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0873 - accuracy: 0.0271 - val_loss: 1.0869 - val_accuracy: 0.0263\n",
            "Epoch 13/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0864 - accuracy: 0.0271 - val_loss: 1.0860 - val_accuracy: 0.0263\n",
            "Epoch 14/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0856 - accuracy: 0.0271 - val_loss: 1.0853 - val_accuracy: 0.0263\n",
            "Epoch 15/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0848 - accuracy: 0.0271 - val_loss: 1.0845 - val_accuracy: 0.0263\n",
            "Epoch 16/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0841 - accuracy: 0.0271 - val_loss: 1.0839 - val_accuracy: 0.0263\n",
            "Epoch 17/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0835 - accuracy: 0.0271 - val_loss: 1.0832 - val_accuracy: 0.0263\n",
            "Epoch 18/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0829 - accuracy: 0.0271 - val_loss: 1.0827 - val_accuracy: 0.0263\n",
            "Epoch 19/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0823 - accuracy: 0.0271 - val_loss: 1.0821 - val_accuracy: 0.0263\n",
            "Epoch 20/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0818 - accuracy: 0.0271 - val_loss: 1.0816 - val_accuracy: 0.0263\n",
            "Epoch 21/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0813 - accuracy: 0.0271 - val_loss: 1.0812 - val_accuracy: 0.0263\n",
            "Epoch 22/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0809 - accuracy: 0.0271 - val_loss: 1.0807 - val_accuracy: 0.0263\n",
            "Epoch 23/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0804 - accuracy: 0.0271 - val_loss: 1.0803 - val_accuracy: 0.0263\n",
            "Epoch 24/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0801 - accuracy: 0.0271 - val_loss: 1.0800 - val_accuracy: 0.0263\n",
            "Epoch 25/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0797 - accuracy: 0.0271 - val_loss: 1.0796 - val_accuracy: 0.0263\n",
            "Epoch 26/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0794 - accuracy: 0.0271 - val_loss: 1.0793 - val_accuracy: 0.0263\n",
            "Epoch 27/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0791 - accuracy: 0.0271 - val_loss: 1.0790 - val_accuracy: 0.0263\n",
            "Epoch 28/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0788 - accuracy: 0.0271 - val_loss: 1.0788 - val_accuracy: 0.0263\n",
            "Epoch 29/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0786 - accuracy: 0.0271 - val_loss: 1.0785 - val_accuracy: 0.0263\n",
            "Epoch 30/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0783 - accuracy: 0.0271 - val_loss: 1.0783 - val_accuracy: 0.0263\n",
            "Epoch 31/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0781 - accuracy: 0.0271 - val_loss: 1.0781 - val_accuracy: 0.0263\n",
            "Epoch 32/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0779 - accuracy: 0.0271 - val_loss: 1.0779 - val_accuracy: 0.0263\n",
            "Epoch 33/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0777 - accuracy: 0.0271 - val_loss: 1.0777 - val_accuracy: 0.0263\n",
            "Epoch 34/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0776 - accuracy: 0.0271 - val_loss: 1.0776 - val_accuracy: 0.0263\n",
            "Epoch 35/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0774 - accuracy: 0.0271 - val_loss: 1.0774 - val_accuracy: 0.0263\n",
            "Epoch 36/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0773 - accuracy: 0.0271 - val_loss: 1.0773 - val_accuracy: 0.0263\n",
            "Epoch 37/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0772 - accuracy: 0.0271 - val_loss: 1.0772 - val_accuracy: 0.0263\n",
            "Epoch 38/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0771 - accuracy: 0.0271 - val_loss: 1.0771 - val_accuracy: 0.0263\n",
            "Epoch 39/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0770 - accuracy: 0.0271 - val_loss: 1.0770 - val_accuracy: 0.0263\n",
            "Epoch 40/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0769 - accuracy: 0.0271 - val_loss: 1.0769 - val_accuracy: 0.0263\n",
            "Epoch 41/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0768 - accuracy: 0.0271 - val_loss: 1.0768 - val_accuracy: 0.0263\n",
            "Epoch 42/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0767 - accuracy: 0.0271 - val_loss: 1.0767 - val_accuracy: 0.0263\n",
            "Epoch 43/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0766 - accuracy: 0.0271 - val_loss: 1.0767 - val_accuracy: 0.0263\n",
            "Epoch 44/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0766 - accuracy: 0.0271 - val_loss: 1.0766 - val_accuracy: 0.0263\n",
            "Epoch 45/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0765 - accuracy: 0.0271 - val_loss: 1.0766 - val_accuracy: 0.0263\n",
            "Epoch 46/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0765 - accuracy: 0.0271 - val_loss: 1.0765 - val_accuracy: 0.0263\n",
            "Epoch 47/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0764 - accuracy: 0.0271 - val_loss: 1.0765 - val_accuracy: 0.0263\n",
            "Epoch 48/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0764 - accuracy: 0.0271 - val_loss: 1.0764 - val_accuracy: 0.0263\n",
            "Epoch 49/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0763 - accuracy: 0.0271 - val_loss: 1.0764 - val_accuracy: 0.0263\n",
            "Epoch 50/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0763 - accuracy: 0.0271 - val_loss: 1.0764 - val_accuracy: 0.0263\n",
            "Epoch 51/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0763 - accuracy: 0.0271 - val_loss: 1.0764 - val_accuracy: 0.0263\n",
            "Epoch 52/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0763 - accuracy: 0.0271 - val_loss: 1.0763 - val_accuracy: 0.0263\n",
            "Epoch 53/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0271 - val_loss: 1.0763 - val_accuracy: 0.0263\n",
            "Epoch 54/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0271 - val_loss: 1.0763 - val_accuracy: 0.0263\n",
            "Epoch 55/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0271 - val_loss: 1.0763 - val_accuracy: 0.0263\n",
            "Epoch 56/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0271 - val_loss: 1.0763 - val_accuracy: 0.0263\n",
            "Epoch 57/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 58/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0762 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 59/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 60/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 61/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 62/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 63/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 64/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 65/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 66/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0762 - val_accuracy: 0.0263\n",
            "Epoch 67/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0271 - val_loss: 1.0761 - val_accuracy: 0.0263\n",
            "Epoch 68/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0761 - accuracy: 0.0272 - val_loss: 1.0649 - val_accuracy: 0.0263\n",
            "Epoch 69/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0673 - accuracy: 0.0238 - val_loss: 1.0513 - val_accuracy: 0.0263\n",
            "Epoch 70/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0509 - accuracy: 0.0264 - val_loss: 1.0508 - val_accuracy: 0.0263\n",
            "Epoch 71/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0507 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 72/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 73/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0256 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 74/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 75/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 76/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 77/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 78/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 79/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 80/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 81/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 82/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 83/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 84/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 85/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 86/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 87/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 88/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 89/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 90/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 91/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 92/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 93/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 94/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 95/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 96/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 97/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 98/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 99/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 100/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 101/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 102/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 103/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 104/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 105/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 106/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 107/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 108/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 109/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 110/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 111/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 112/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 113/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 114/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 115/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 116/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 117/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 118/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 119/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 120/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 121/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 122/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 123/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 124/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 125/350\n",
            "87/87 [==============================] - 24s 276ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 126/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 127/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 128/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 129/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 130/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 131/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 132/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 133/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 134/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 135/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 136/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 137/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 138/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 139/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 140/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 141/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 142/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 143/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 144/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 145/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 146/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 147/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 148/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 149/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 150/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 151/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 152/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 153/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 154/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 155/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 156/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 157/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 158/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 159/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 160/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 161/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 162/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 163/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 164/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 165/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 166/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 167/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 168/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 169/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 170/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 171/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 172/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 173/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 174/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 175/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 176/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 177/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 178/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 179/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 180/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 181/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 182/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 183/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 184/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 185/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 186/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 187/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 188/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 189/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 190/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 191/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 192/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 193/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 194/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 195/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 196/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 197/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 198/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 199/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 200/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 201/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 202/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 203/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 204/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 205/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 206/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 207/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 208/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 209/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 210/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 211/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 212/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 213/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 214/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 215/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 216/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 217/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 218/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 219/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 220/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 221/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 222/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 223/350\n",
            "87/87 [==============================] - 24s 275ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 224/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 225/350\n",
            "87/87 [==============================] - 24s 274ms/step - loss: 1.0506 - accuracy: 0.0275 - val_loss: 1.0506 - val_accuracy: 0.0263\n",
            "Epoch 226/350\n",
            " 9/87 [==>...........................] - ETA: 20s - loss: 1.0506 - accuracy: 0.0295"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}